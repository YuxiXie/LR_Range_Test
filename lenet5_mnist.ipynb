{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colossalai should be built with cuda extension to use the FP16 optimizer\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "import colossalai\n",
    "from colossalai.core import global_context as gpc\n",
    "from colossalai.utils import MultiTimer, get_dataloader\n",
    "from colossalai.logging import get_dist_logger\n",
    "from colossalai.trainer import Trainer, hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist_data():\n",
    "    # load MNIST dataset\n",
    "    train_dataset = MNIST(\n",
    "        root='./tmp/', train=True, download=True, \n",
    "        transform=transforms.Compose([\n",
    "            transforms.Resize((32, 32)),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "    )    \n",
    "    test_dataset = MNIST(\n",
    "        root='./tmp/', train=False, download=True, \n",
    "        transform=transforms.Compose([\n",
    "            transforms.Resize((32, 32)),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "    )\n",
    "    \n",
    "    # build dataloader\n",
    "    train_dataloader = get_dataloader(dataset=train_dataset,\n",
    "                                      shuffle=True,\n",
    "                                      batch_size=gpc.config.BATCH_SIZE,\n",
    "                                      num_workers=1,\n",
    "                                      pin_memory=True)\n",
    "    test_dataloader = get_dataloader(dataset=test_dataset,\n",
    "                                     add_sampler=False,\n",
    "                                     batch_size=gpc.config.BATCH_SIZE,\n",
    "                                     num_workers=1,\n",
    "                                     pin_memory=True)\n",
    "\n",
    "    return train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_classes):\n",
    "        super(LeNet5, self).__init__()\n",
    "        \n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=120, out_features=84),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=84, out_features=n_classes),\n",
    "        )\n",
    "        \n",
    "        # self.feature_extractor = nn.Sequential(\n",
    "        #     nn.Conv2d(in_channels=1, out_channels=50, kernel_size=3, padding=1),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.MaxPool2d(2, 2),\n",
    "        #     nn.Conv2d(in_channels=50, out_channels=100, kernel_size=3, padding=1),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.MaxPool2d(2, 2)\n",
    "        # )\n",
    "        \n",
    "        # self.classifier = nn.Sequential(\n",
    "        #     nn.Linear(in_features=4900, out_features=100),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(in_features=100, out_features=n_classes)\n",
    "        # )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        logits = self.classifier(x)\n",
    "        \n",
    "        # x = self.feature_extractor(x)\n",
    "        # x = x.view(-1, 4900)\n",
    "        # logits = self.classifier(x)\n",
    "        \n",
    "        probs = F.softmax(logits, dim=1)\n",
    "    \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, test_dataloader,\n",
    "          num_epochs, optim_type='SGD',\n",
    "          lr_start=1, lr_low=1e-5, lr_high=10,\n",
    "          lr_sch='None', lr_sch_params=None,\n",
    "          eval=False):\n",
    "    ###===== Build Model =====###\n",
    "    model = LeNet5(n_classes=10)\n",
    "\n",
    "    ###===== Set Loss =====###\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    ###===== Set Optimizer =====###\n",
    "    if optim_type == 'SGD':\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr_start, \n",
    "                                    momentum=0.9, \n",
    "                                    weight_decay=5e-4)\n",
    "    elif optim_type == 'Adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr_start, \n",
    "                                     betas=[0.9, 0.999],\n",
    "                                     eps=1e-9)\n",
    "    \n",
    "    ###===== Learning Rate Setting =====###\n",
    "    def exp_increase_lr(batch):\n",
    "        ''' exponentially increase learning rate from low to high\n",
    "        '''\n",
    "        low = math.log2(lr_low)\n",
    "        high = math.log2(lr_high)\n",
    "        \n",
    "        total_size = len(train_dataloader)\n",
    "        index = low + (high - low) * batch / (total_size * gpc.config.NUM_EPOCHS)\n",
    "        updated_lr = 2 ** index\n",
    "\n",
    "        return updated_lr\n",
    "\n",
    "    ##=== set lr scheduler ===##\n",
    "    if lr_sch == 'RangeTest':\n",
    "        lr_scheduler = optim.lr_scheduler.LambdaLR(optimizer=optimizer, \n",
    "                                                   lr_lambda=exp_increase_lr)\n",
    "    elif lr_sch == 'MultiStep':\n",
    "        lr_scheduler = optim.lr_scheduler.MultiStepLR(optimizer=optimizer, \n",
    "                                                      milestones=lr_sch_params['milestones'])\n",
    "    elif lr_sch == 'OneCycle':\n",
    "        lr_scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer,\n",
    "                                                     max_lr=lr_sch_params['max_lr'],\n",
    "                                                     final_div_factor=lr_sch_params['final_div_factor'],\n",
    "                                                     steps_per_epoch=len(train_dataloader),\n",
    "                                                     epochs=num_epochs)\n",
    "    else:\n",
    "        lr_scheduler = optim.lr_scheduler.MultiStepLR(optimizer=optimizer, \n",
    "                                                      milestones=[])\n",
    "    \n",
    "    ###===== Training =====###\n",
    "    timer = MultiTimer()\n",
    "    logger = get_dist_logger()\n",
    "\n",
    "    engine, train_dataloader, test_dataloader, _ = \\\n",
    "        colossalai.initialize(model, optimizer, criterion,\n",
    "                            train_dataloader, test_dataloader)\n",
    "\n",
    "    ##=== create a trainer object ===##\n",
    "    trainer = Trainer(engine=engine, timer=timer,\n",
    "                      logger=logger)\n",
    "\n",
    "    ##=== define the hooks to attach to the trainer ===##\n",
    "    if lr_sch == 'RangeTest':\n",
    "        log_dir = './tb_logs/' + f'{optim_type}_{lr_low}_{lr_high}_{num_epochs}'\n",
    "    else:\n",
    "        log_dir = './tb_logs/' + f'{optim_type}_{lr_sch}_{num_epochs}'\n",
    "    hook_list = [\n",
    "        hooks.LossHook(),\n",
    "        hooks.LRSchedulerHook(lr_scheduler=lr_scheduler, \n",
    "                              by_epoch=True if lr_sch in ['MultiStep', 'None'] else False),\n",
    "        \n",
    "        hooks.LogMetricByEpochHook(logger),\n",
    "        hooks.LogMemoryByEpochHook(logger),\n",
    "        hooks.LogTimingByEpochHook(timer, logger),\n",
    "\n",
    "        hooks.TensorboardHook(log_dir=log_dir, ranks=[0]),\n",
    "        # hooks.SaveCheckpointHook(checkpoint_dir='./ckpt')\n",
    "    ]\n",
    "\n",
    "    ##=== start training ===##\n",
    "    trainer.fit(train_dataloader=train_dataloader,\n",
    "                epochs=gpc.config.NUM_EPOCHS,\n",
    "                test_dataloader=test_dataloader,\n",
    "                test_interval=1,\n",
    "                hooks=hook_list,\n",
    "                display_progress=True)\n",
    "    \n",
    "    ##=== evaluating ===##\n",
    "    if eval:\n",
    "        GTs, PRs = [], []\n",
    "        for batch in test_dataloader:\n",
    "            inputs, labels = batch\n",
    "            logits = trainer.engine._model(inputs.to(torch.device('cuda')))\n",
    "            outputs = logits.cpu().argmax(-1)\n",
    "            PRs.append(outputs)\n",
    "            GTs.append(labels)\n",
    "        GTs = torch.cat(GTs, dim=0)\n",
    "        PRs = torch.cat(PRs, dim=0)\n",
    "        \n",
    "        accu = PRs.eq(GTs).sum() / len(PRs)\n",
    "        \n",
    "        print('Accuracy on Testing Dataset: {:.3f}%'.format(accu * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "colossalai - root - 2022-04-01 23:24:33,543 INFO: Added key: store_based_barrier_key:1 to store for rank: 0\n",
      "colossalai - root - 2022-04-01 23:24:33,545 INFO: Added key: store_based_barrier_key:2 to store for rank: 0\n",
      "colossalai - root - 2022-04-01 23:24:33,546 INFO: Added key: store_based_barrier_key:3 to store for rank: 0\n",
      "colossalai - root - 2022-04-01 23:24:33,548 INFO: Added key: store_based_barrier_key:4 to store for rank: 0\n",
      "colossalai - colossalai - 2022-04-01 23:24:33,555 INFO: process rank 0 is bound to device 0\n",
      "colossalai - colossalai - 2022-04-01 23:24:33,557 INFO: initialized seed on rank 0, numpy: 1024, python random: 1024, ParallelMode.DATA: 1024, ParallelMode.TENSOR: 1024,the default parallel seed is ParallelMode.DATA.\n",
      "colossalai - colossalai - 2022-04-01 23:24:33,558 INFO: Distributed environment is initialized, data parallel size: 1, pipeline parallel size: 1, tensor parallel size: 1\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_epochs = 30\n",
    "\n",
    "###===== Set Configuration =====###\n",
    "config = {\n",
    "    'BATCH_SIZE':batch_size,\n",
    "    'NUM_EPOCHS':num_epochs\n",
    "}\n",
    "colossalai.launch(config=config, rank=0, world_size=1,\n",
    "                  host='127.0.0.1', port=1234)\n",
    "\n",
    "###===== Load Dataset =====###\n",
    "train_dataloader, test_dataloader = get_mnist_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### LR Range Test\n",
    "1. SGD\n",
    "2. Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###===== LR Range Test (SGD) =====###\n",
    "train(train_dataloader, test_dataloader,\n",
    "      num_epochs=10, \n",
    "      optim_type='SGD',\n",
    "      lr_start=1,\n",
    "      lr_low=1e-6, \n",
    "      lr_high=1.18, \n",
    "      lr_sch='RangeTest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###===== LR Range Test (Adam) =====###\n",
    "train(train_dataloader, test_dataloader,\n",
    "      num_epochs=10, \n",
    "      optim_type='Adam',\n",
    "      lr_start=1,\n",
    "      lr_low=1e-8, \n",
    "      lr_high=0.12, \n",
    "      lr_sch='RangeTest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Training (SGD)\n",
    "1. No Scheduling\n",
    "2. MultiStep\n",
    "3. OneCycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###===== No Scheduling =====###    \n",
    "train(train_dataloader, test_dataloader,\n",
    "      num_epochs=30, \n",
    "      optim_type='SGD',\n",
    "      lr_start=0.1,\n",
    "      lr_sch='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "colossalai - colossalai - 2022-04-01 23:25:10,500 INFO: \n",
      "========== Your Config ========\n",
      "{'BATCH_SIZE': 128, 'NUM_EPOCHS': 30}\n",
      "================================\n",
      "\n",
      "colossalai - colossalai - 2022-04-01 23:25:10,501 INFO: cuDNN benchmark = True, deterministic = False\n",
      "colossalai - colossalai - 2022-04-01 23:25:13,806 WARNING: No PyTorch DDP or gradient handler is set up, please make sure you do not need to all-reduce the gradients after a training step.\n",
      "colossalai - colossalai - 2022-04-01 23:25:14,196 INFO: Using LossHook for training, priority = 0\n",
      "colossalai - colossalai - 2022-04-01 23:25:14,198 INFO: Using LRSchedulerHook for training, priority = 1\n",
      "colossalai - colossalai - 2022-04-01 23:25:14,198 INFO: Using LogMetricByEpochHook for training, priority = 10\n",
      "colossalai - colossalai - 2022-04-01 23:25:14,199 INFO: Using LogMemoryByEpochHook for training, priority = 10\n",
      "colossalai - colossalai - 2022-04-01 23:25:14,200 INFO: Using LogTimingByEpochHook for training, priority = 10\n",
      "colossalai - colossalai - 2022-04-01 23:25:14,201 INFO: Using TensorboardHook for training, priority = 10\n",
      "colossalai - colossalai - 2022-04-01 23:25:14,201 INFO: Lower value means higher priority for calling hook function\n",
      "colossalai - colossalai - 2022-04-01 23:25:14,205 INFO: Before-train: GPU: allocated 0.24 MB, max allocated 0.24 MB, cached: 2.0 MB, max cached: 2.0 MB\n",
      "[Epoch 0 / Train]: 100%|██████████| 469/469 [00:06<00:00, 76.26it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:25:20,533 INFO: [Epoch 0 / Train]: Loss = 0.28451 | LR = 0.1\n",
      "colossalai - colossalai - 2022-04-01 23:25:20,535 INFO: [Epoch 0 / Train]: GPU: allocated 4.71 MB, max allocated 88.41 MB, cached: 26.0 MB, max cached: 108.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:25:20,536 INFO: [Epoch 0 / Train]: Train-epoch: last = 6.1509 s, mean = 6.1509 s | Train-step: last = 0.025055 s, mean = 0.01235 s | #steps/epoch = 469\n",
      "[Epoch 0 / Test]: 100%|██████████| 79/79 [00:01<00:00, 72.09it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:25:21,761 INFO: [Epoch 0 / Test]: Loss = 0.089456\n",
      "colossalai - colossalai - 2022-04-01 23:25:21,763 INFO: [Epoch 0 / Test]: Test-epoch: last = 1.0965 s, mean = 1.0965 s | Test-step: last = 0.0069404 s, mean = 0.013451 s\n",
      "colossalai - colossalai - 2022-04-01 23:25:21,767 INFO: [Epoch 0 / Test]: GPU: allocated 0.72 MB, max allocated 17.84 MB, cached: 24.0 MB, max cached: 26.0 MB\n",
      "[Epoch 1 / Train]: 100%|██████████| 469/469 [00:06<00:00, 76.05it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:25:28,072 INFO: [Epoch 1 / Train]: Loss = 0.080848 | LR = 0.1\n",
      "colossalai - colossalai - 2022-04-01 23:25:28,075 INFO: [Epoch 1 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:25:28,076 INFO: [Epoch 1 / Train]: Train-epoch: last = 6.1678 s, mean = 6.1678 s | Train-step: last = 0.0067754 s, mean = 0.012385 s | #steps/epoch = 469\n",
      "[Epoch 1 / Test]: 100%|██████████| 79/79 [00:01<00:00, 73.89it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:25:29,261 INFO: [Epoch 1 / Test]: Loss = 0.057626\n",
      "colossalai - colossalai - 2022-04-01 23:25:29,262 INFO: [Epoch 1 / Test]: Test-epoch: last = 1.0694 s, mean = 1.0694 s | Test-step: last = 0.0022807 s, mean = 0.01316 s\n",
      "colossalai - colossalai - 2022-04-01 23:25:29,265 INFO: [Epoch 1 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 2 / Train]: 100%|██████████| 469/469 [00:06<00:00, 76.29it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:25:35,560 INFO: [Epoch 2 / Train]: Loss = 0.061492 | LR = 0.1\n",
      "colossalai - colossalai - 2022-04-01 23:25:35,562 INFO: [Epoch 2 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:25:35,563 INFO: [Epoch 2 / Train]: Train-epoch: last = 6.1478 s, mean = 6.1478 s | Train-step: last = 0.0075629 s, mean = 0.012389 s | #steps/epoch = 469\n",
      "[Epoch 2 / Test]: 100%|██████████| 79/79 [00:01<00:00, 70.14it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:25:36,806 INFO: [Epoch 2 / Test]: Loss = 0.051513\n",
      "colossalai - colossalai - 2022-04-01 23:25:36,807 INFO: [Epoch 2 / Test]: Test-epoch: last = 1.1271 s, mean = 1.1271 s | Test-step: last = 0.0025001 s, mean = 0.013873 s\n",
      "colossalai - colossalai - 2022-04-01 23:25:36,810 INFO: [Epoch 2 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 3 / Train]: 100%|██████████| 469/469 [00:06<00:00, 74.93it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:25:43,175 INFO: [Epoch 3 / Train]: Loss = 0.050652 | LR = 0.1\n",
      "colossalai - colossalai - 2022-04-01 23:25:43,178 INFO: [Epoch 3 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:25:43,180 INFO: [Epoch 3 / Train]: Train-epoch: last = 6.2601 s, mean = 6.2601 s | Train-step: last = 0.012276 s, mean = 0.012447 s | #steps/epoch = 469\n",
      "[Epoch 3 / Test]: 100%|██████████| 79/79 [00:01<00:00, 78.06it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:25:44,301 INFO: [Epoch 3 / Test]: Loss = 0.044951\n",
      "colossalai - colossalai - 2022-04-01 23:25:44,302 INFO: [Epoch 3 / Test]: Test-epoch: last = 1.0126 s, mean = 1.0126 s | Test-step: last = 0.0020881 s, mean = 0.012511 s\n",
      "colossalai - colossalai - 2022-04-01 23:25:44,309 INFO: [Epoch 3 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 4 / Train]: 100%|██████████| 469/469 [00:06<00:00, 76.23it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:25:50,569 INFO: [Epoch 4 / Train]: Loss = 0.046673 | LR = 0.1\n",
      "colossalai - colossalai - 2022-04-01 23:25:50,570 INFO: [Epoch 4 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:25:50,571 INFO: [Epoch 4 / Train]: Train-epoch: last = 6.1532 s, mean = 6.1532 s | Train-step: last = 0.0060608 s, mean = 0.012445 s | #steps/epoch = 469\n",
      "[Epoch 4 / Test]: 100%|██████████| 79/79 [00:01<00:00, 70.46it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:25:51,794 INFO: [Epoch 4 / Test]: Loss = 0.048691\n",
      "colossalai - colossalai - 2022-04-01 23:25:51,796 INFO: [Epoch 4 / Test]: Test-epoch: last = 1.122 s, mean = 1.122 s | Test-step: last = 0.0020823 s, mean = 0.013854 s\n",
      "colossalai - colossalai - 2022-04-01 23:25:51,799 INFO: [Epoch 4 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 5 / Train]: 100%|██████████| 469/469 [00:06<00:00, 75.85it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:25:58,099 INFO: [Epoch 5 / Train]: Loss = 0.043162 | LR = 0.1\n",
      "colossalai - colossalai - 2022-04-01 23:25:58,102 INFO: [Epoch 5 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:25:58,103 INFO: [Epoch 5 / Train]: Train-epoch: last = 6.1843 s, mean = 6.1843 s | Train-step: last = 0.0086682 s, mean = 0.012458 s | #steps/epoch = 469\n",
      "[Epoch 5 / Test]: 100%|██████████| 79/79 [00:01<00:00, 75.41it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:25:59,267 INFO: [Epoch 5 / Test]: Loss = 0.047684\n",
      "colossalai - colossalai - 2022-04-01 23:25:59,268 INFO: [Epoch 5 / Test]: Test-epoch: last = 1.0488 s, mean = 1.0488 s | Test-step: last = 0.0022342 s, mean = 0.012935 s\n",
      "colossalai - colossalai - 2022-04-01 23:25:59,272 INFO: [Epoch 5 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 6 / Train]: 100%|██████████| 469/469 [00:06<00:00, 73.42it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:26:05,781 INFO: [Epoch 6 / Train]: Loss = 0.040135 | LR = 0.1\n",
      "colossalai - colossalai - 2022-04-01 23:26:05,784 INFO: [Epoch 6 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:26:05,787 INFO: [Epoch 6 / Train]: Train-epoch: last = 6.3891 s, mean = 6.3891 s | Train-step: last = 0.0096371 s, mean = 0.012528 s | #steps/epoch = 469\n",
      "[Epoch 6 / Test]: 100%|██████████| 79/79 [00:01<00:00, 71.89it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:26:07,000 INFO: [Epoch 6 / Test]: Loss = 0.036198\n",
      "colossalai - colossalai - 2022-04-01 23:26:07,001 INFO: [Epoch 6 / Test]: Test-epoch: last = 1.1001 s, mean = 1.1001 s | Test-step: last = 0.0048654 s, mean = 0.013554 s\n",
      "colossalai - colossalai - 2022-04-01 23:26:07,004 INFO: [Epoch 6 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 7 / Train]: 100%|██████████| 469/469 [00:06<00:00, 76.39it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:26:13,252 INFO: [Epoch 7 / Train]: Loss = 0.040001 | LR = 0.1\n",
      "colossalai - colossalai - 2022-04-01 23:26:13,255 INFO: [Epoch 7 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:26:13,257 INFO: [Epoch 7 / Train]: Train-epoch: last = 6.1416 s, mean = 6.1416 s | Train-step: last = 0.010574 s, mean = 0.012508 s | #steps/epoch = 469\n",
      "[Epoch 7 / Test]: 100%|██████████| 79/79 [00:01<00:00, 74.07it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:26:14,430 INFO: [Epoch 7 / Test]: Loss = 0.047513\n",
      "colossalai - colossalai - 2022-04-01 23:26:14,432 INFO: [Epoch 7 / Test]: Test-epoch: last = 1.0675 s, mean = 1.0675 s | Test-step: last = 0.002074 s, mean = 0.013121 s\n",
      "colossalai - colossalai - 2022-04-01 23:26:14,436 INFO: [Epoch 7 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 8 / Train]: 100%|██████████| 469/469 [00:06<00:00, 76.74it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:26:20,679 INFO: [Epoch 8 / Train]: Loss = 0.04056 | LR = 0.1\n",
      "colossalai - colossalai - 2022-04-01 23:26:20,682 INFO: [Epoch 8 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:26:20,684 INFO: [Epoch 8 / Train]: Train-epoch: last = 6.1121 s, mean = 6.1121 s | Train-step: last = 0.009125 s, mean = 0.012491 s | #steps/epoch = 469\n",
      "[Epoch 8 / Test]: 100%|██████████| 79/79 [00:01<00:00, 75.32it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:26:21,848 INFO: [Epoch 8 / Test]: Loss = 0.037793\n",
      "colossalai - colossalai - 2022-04-01 23:26:21,849 INFO: [Epoch 8 / Test]: Test-epoch: last = 1.0503 s, mean = 1.0503 s | Test-step: last = 0.00335 s, mean = 0.01296 s\n",
      "colossalai - colossalai - 2022-04-01 23:26:21,855 INFO: [Epoch 8 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 9 / Train]: 100%|██████████| 469/469 [00:06<00:00, 76.57it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:26:28,104 INFO: [Epoch 9 / Train]: Loss = 0.035941 | LR = 0.1\n",
      "colossalai - colossalai - 2022-04-01 23:26:28,105 INFO: [Epoch 9 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:26:28,106 INFO: [Epoch 9 / Train]: Train-epoch: last = 6.1252 s, mean = 6.1252 s | Train-step: last = 0.0069029 s, mean = 0.01248 s | #steps/epoch = 469\n",
      "[Epoch 9 / Test]: 100%|██████████| 79/79 [00:01<00:00, 74.48it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:26:29,270 INFO: [Epoch 9 / Test]: Loss = 0.041331\n",
      "colossalai - colossalai - 2022-04-01 23:26:29,271 INFO: [Epoch 9 / Test]: Test-epoch: last = 1.0618 s, mean = 1.0618 s | Test-step: last = 0.0021541 s, mean = 0.013061 s\n",
      "colossalai - colossalai - 2022-04-01 23:26:29,275 INFO: [Epoch 9 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 10 / Train]: 100%|██████████| 469/469 [00:06<00:00, 76.98it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:26:35,478 INFO: [Epoch 10 / Train]: Loss = 0.037759 | LR = 0.1\n",
      "colossalai - colossalai - 2022-04-01 23:26:35,481 INFO: [Epoch 10 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:26:35,483 INFO: [Epoch 10 / Train]: Train-epoch: last = 6.094 s, mean = 6.094 s | Train-step: last = 0.008724 s, mean = 0.012461 s | #steps/epoch = 469\n",
      "[Epoch 10 / Test]: 100%|██████████| 79/79 [00:01<00:00, 71.93it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:26:36,704 INFO: [Epoch 10 / Test]: Loss = 0.034546\n",
      "colossalai - colossalai - 2022-04-01 23:26:36,706 INFO: [Epoch 10 / Test]: Test-epoch: last = 1.0996 s, mean = 1.0996 s | Test-step: last = 0.0021889 s, mean = 0.013494 s\n",
      "colossalai - colossalai - 2022-04-01 23:26:36,709 INFO: [Epoch 10 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 11 / Train]: 100%|██████████| 469/469 [00:06<00:00, 75.27it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:26:43,085 INFO: [Epoch 11 / Train]: Loss = 0.037257 | LR = 0.1\n",
      "colossalai - colossalai - 2022-04-01 23:26:43,088 INFO: [Epoch 11 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:26:43,089 INFO: [Epoch 11 / Train]: Train-epoch: last = 6.2307 s, mean = 6.2307 s | Train-step: last = 0.0090737 s, mean = 0.01247 s | #steps/epoch = 469\n",
      "[Epoch 11 / Test]: 100%|██████████| 79/79 [00:01<00:00, 73.11it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:26:44,275 INFO: [Epoch 11 / Test]: Loss = 0.04334\n",
      "colossalai - colossalai - 2022-04-01 23:26:44,275 INFO: [Epoch 11 / Test]: Test-epoch: last = 1.0811 s, mean = 1.0811 s | Test-step: last = 0.0014648 s, mean = 0.01337 s\n",
      "colossalai - colossalai - 2022-04-01 23:26:44,278 INFO: [Epoch 11 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 12 / Train]: 100%|██████████| 469/469 [00:06<00:00, 77.11it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:26:50,467 INFO: [Epoch 12 / Train]: Loss = 0.034405 | LR = 0.1\n",
      "colossalai - colossalai - 2022-04-01 23:26:50,469 INFO: [Epoch 12 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:26:50,470 INFO: [Epoch 12 / Train]: Train-epoch: last = 6.0833 s, mean = 6.0833 s | Train-step: last = 0.0096843 s, mean = 0.012455 s | #steps/epoch = 469\n",
      "[Epoch 12 / Test]: 100%|██████████| 79/79 [00:01<00:00, 70.90it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:26:51,689 INFO: [Epoch 12 / Test]: Loss = 0.035826\n",
      "colossalai - colossalai - 2022-04-01 23:26:51,690 INFO: [Epoch 12 / Test]: Test-epoch: last = 1.1146 s, mean = 1.1146 s | Test-step: last = 0.001492 s, mean = 0.013814 s\n",
      "colossalai - colossalai - 2022-04-01 23:26:51,691 INFO: [Epoch 12 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 13 / Train]: 100%|██████████| 469/469 [00:06<00:00, 76.73it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:26:57,932 INFO: [Epoch 13 / Train]: Loss = 0.035504 | LR = 0.1\n",
      "colossalai - colossalai - 2022-04-01 23:26:57,935 INFO: [Epoch 13 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:26:57,936 INFO: [Epoch 13 / Train]: Train-epoch: last = 6.1135 s, mean = 6.1135 s | Train-step: last = 0.0086756 s, mean = 0.012446 s | #steps/epoch = 469\n",
      "[Epoch 13 / Test]: 100%|██████████| 79/79 [00:01<00:00, 72.89it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:26:59,132 INFO: [Epoch 13 / Test]: Loss = 0.036683\n",
      "colossalai - colossalai - 2022-04-01 23:26:59,133 INFO: [Epoch 13 / Test]: Test-epoch: last = 1.0844 s, mean = 1.0844 s | Test-step: last = 0.0021269 s, mean = 0.01338 s\n",
      "colossalai - colossalai - 2022-04-01 23:26:59,136 INFO: [Epoch 13 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 14 / Train]: 100%|██████████| 469/469 [00:06<00:00, 76.08it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:27:05,413 INFO: [Epoch 14 / Train]: Loss = 0.034653 | LR = 0.01\n",
      "colossalai - colossalai - 2022-04-01 23:27:05,415 INFO: [Epoch 14 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:27:05,416 INFO: [Epoch 14 / Train]: Train-epoch: last = 6.1649 s, mean = 6.1649 s | Train-step: last = 0.0084991 s, mean = 0.012451 s | #steps/epoch = 469\n",
      "[Epoch 14 / Test]: 100%|██████████| 79/79 [00:01<00:00, 74.65it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:27:06,577 INFO: [Epoch 14 / Test]: Loss = 0.047696\n",
      "colossalai - colossalai - 2022-04-01 23:27:06,578 INFO: [Epoch 14 / Test]: Test-epoch: last = 1.0587 s, mean = 1.0587 s | Test-step: last = 0.0021031 s, mean = 0.013075 s\n",
      "colossalai - colossalai - 2022-04-01 23:27:06,582 INFO: [Epoch 14 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 15 / Train]: 100%|██████████| 469/469 [00:06<00:00, 77.04it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:27:12,777 INFO: [Epoch 15 / Train]: Loss = 0.018148 | LR = 0.01\n",
      "colossalai - colossalai - 2022-04-01 23:27:12,780 INFO: [Epoch 15 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:27:12,782 INFO: [Epoch 15 / Train]: Train-epoch: last = 6.0892 s, mean = 6.0892 s | Train-step: last = 0.0084102 s, mean = 0.01244 s | #steps/epoch = 469\n",
      "[Epoch 15 / Test]: 100%|██████████| 79/79 [00:01<00:00, 74.18it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:27:13,970 INFO: [Epoch 15 / Test]: Loss = 0.024281\n",
      "colossalai - colossalai - 2022-04-01 23:27:13,971 INFO: [Epoch 15 / Test]: Test-epoch: last = 1.0653 s, mean = 1.0653 s | Test-step: last = 0.0020511 s, mean = 0.013167 s\n",
      "colossalai - colossalai - 2022-04-01 23:27:13,974 INFO: [Epoch 15 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 16 / Train]: 100%|██████████| 469/469 [00:06<00:00, 76.99it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:27:20,187 INFO: [Epoch 16 / Train]: Loss = 0.014724 | LR = 0.01\n",
      "colossalai - colossalai - 2022-04-01 23:27:20,190 INFO: [Epoch 16 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:27:20,192 INFO: [Epoch 16 / Train]: Train-epoch: last = 6.0926 s, mean = 6.0926 s | Train-step: last = 0.0085232 s, mean = 0.012429 s | #steps/epoch = 469\n",
      "[Epoch 16 / Test]: 100%|██████████| 79/79 [00:01<00:00, 74.22it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:27:21,368 INFO: [Epoch 16 / Test]: Loss = 0.023359\n",
      "colossalai - colossalai - 2022-04-01 23:27:21,370 INFO: [Epoch 16 / Test]: Test-epoch: last = 1.0648 s, mean = 1.0648 s | Test-step: last = 0.0023751 s, mean = 0.013077 s\n",
      "colossalai - colossalai - 2022-04-01 23:27:21,374 INFO: [Epoch 16 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 17 / Train]: 100%|██████████| 469/469 [00:05<00:00, 79.13it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:27:27,414 INFO: [Epoch 17 / Train]: Loss = 0.01395 | LR = 0.01\n",
      "colossalai - colossalai - 2022-04-01 23:27:27,419 INFO: [Epoch 17 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:27:27,420 INFO: [Epoch 17 / Train]: Train-epoch: last = 5.9281 s, mean = 5.9281 s | Train-step: last = 0.0088043 s, mean = 0.012402 s | #steps/epoch = 469\n",
      "[Epoch 17 / Test]: 100%|██████████| 79/79 [00:01<00:00, 76.01it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:27:28,573 INFO: [Epoch 17 / Test]: Loss = 0.023397\n",
      "colossalai - colossalai - 2022-04-01 23:27:28,575 INFO: [Epoch 17 / Test]: Test-epoch: last = 1.0403 s, mean = 1.0403 s | Test-step: last = 0.0020566 s, mean = 0.012818 s\n",
      "colossalai - colossalai - 2022-04-01 23:27:28,578 INFO: [Epoch 17 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 18 / Train]: 100%|██████████| 469/469 [00:06<00:00, 77.35it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:27:34,757 INFO: [Epoch 18 / Train]: Loss = 0.013637 | LR = 0.01\n",
      "colossalai - colossalai - 2022-04-01 23:27:34,760 INFO: [Epoch 18 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:27:34,762 INFO: [Epoch 18 / Train]: Train-epoch: last = 6.0645 s, mean = 6.0645 s | Train-step: last = 0.0088236 s, mean = 0.012394 s | #steps/epoch = 469\n",
      "[Epoch 18 / Test]: 100%|██████████| 79/79 [00:01<00:00, 75.29it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:27:35,940 INFO: [Epoch 18 / Test]: Loss = 0.023848\n",
      "colossalai - colossalai - 2022-04-01 23:27:35,941 INFO: [Epoch 18 / Test]: Test-epoch: last = 1.0503 s, mean = 1.0503 s | Test-step: last = 0.0021102 s, mean = 0.012904 s\n",
      "colossalai - colossalai - 2022-04-01 23:27:35,945 INFO: [Epoch 18 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 19 / Train]: 100%|██████████| 469/469 [00:06<00:00, 75.88it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:27:42,234 INFO: [Epoch 19 / Train]: Loss = 0.013472 | LR = 0.01\n",
      "colossalai - colossalai - 2022-04-01 23:27:42,236 INFO: [Epoch 19 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:27:42,238 INFO: [Epoch 19 / Train]: Train-epoch: last = 6.1814 s, mean = 6.1814 s | Train-step: last = 0.010015 s, mean = 0.012399 s | #steps/epoch = 469\n",
      "[Epoch 19 / Test]: 100%|██████████| 79/79 [00:01<00:00, 74.62it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:27:43,415 INFO: [Epoch 19 / Test]: Loss = 0.023398\n",
      "colossalai - colossalai - 2022-04-01 23:27:43,416 INFO: [Epoch 19 / Test]: Test-epoch: last = 1.0596 s, mean = 1.0596 s | Test-step: last = 0.0020993 s, mean = 0.013071 s\n",
      "colossalai - colossalai - 2022-04-01 23:27:43,420 INFO: [Epoch 19 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 20 / Train]: 100%|██████████| 469/469 [00:06<00:00, 74.89it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:27:49,792 INFO: [Epoch 20 / Train]: Loss = 0.013485 | LR = 0.01\n",
      "colossalai - colossalai - 2022-04-01 23:27:49,795 INFO: [Epoch 20 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:27:49,796 INFO: [Epoch 20 / Train]: Train-epoch: last = 6.264 s, mean = 6.264 s | Train-step: last = 0.01241 s, mean = 0.01241 s | #steps/epoch = 469\n",
      "[Epoch 20 / Test]: 100%|██████████| 79/79 [00:01<00:00, 73.98it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:27:50,971 INFO: [Epoch 20 / Test]: Loss = 0.023285\n",
      "colossalai - colossalai - 2022-04-01 23:27:50,972 INFO: [Epoch 20 / Test]: Test-epoch: last = 1.0687 s, mean = 1.0687 s | Test-step: last = 0.0020695 s, mean = 0.01317 s\n",
      "colossalai - colossalai - 2022-04-01 23:27:50,976 INFO: [Epoch 20 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 21 / Train]: 100%|██████████| 469/469 [00:06<00:00, 76.39it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:27:57,224 INFO: [Epoch 21 / Train]: Loss = 0.013438 | LR = 0.01\n",
      "colossalai - colossalai - 2022-04-01 23:27:57,227 INFO: [Epoch 21 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:27:57,228 INFO: [Epoch 21 / Train]: Train-epoch: last = 6.1406 s, mean = 6.1406 s | Train-step: last = 0.0083222 s, mean = 0.012408 s | #steps/epoch = 469\n",
      "[Epoch 21 / Test]: 100%|██████████| 79/79 [00:01<00:00, 72.70it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:27:58,420 INFO: [Epoch 21 / Test]: Loss = 0.024226\n",
      "colossalai - colossalai - 2022-04-01 23:27:58,422 INFO: [Epoch 21 / Test]: Test-epoch: last = 1.0877 s, mean = 1.0877 s | Test-step: last = 0.0020702 s, mean = 0.013393 s\n",
      "colossalai - colossalai - 2022-04-01 23:27:58,426 INFO: [Epoch 21 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 22 / Train]: 100%|██████████| 469/469 [00:06<00:00, 74.28it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:28:04,857 INFO: [Epoch 22 / Train]: Loss = 0.013451 | LR = 0.01\n",
      "colossalai - colossalai - 2022-04-01 23:28:04,860 INFO: [Epoch 22 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:28:04,862 INFO: [Epoch 22 / Train]: Train-epoch: last = 6.315 s, mean = 6.315 s | Train-step: last = 0.008714 s, mean = 0.012423 s | #steps/epoch = 469\n",
      "[Epoch 22 / Test]: 100%|██████████| 79/79 [00:01<00:00, 73.70it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:28:06,044 INFO: [Epoch 22 / Test]: Loss = 0.023819\n",
      "colossalai - colossalai - 2022-04-01 23:28:06,044 INFO: [Epoch 22 / Test]: Test-epoch: last = 1.0725 s, mean = 1.0725 s | Test-step: last = 0.0020494 s, mean = 0.01324 s\n",
      "colossalai - colossalai - 2022-04-01 23:28:06,048 INFO: [Epoch 22 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 23 / Train]: 100%|██████████| 469/469 [00:06<00:00, 73.95it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:28:12,507 INFO: [Epoch 23 / Train]: Loss = 0.013505 | LR = 0.01\n",
      "colossalai - colossalai - 2022-04-01 23:28:12,509 INFO: [Epoch 23 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:28:12,511 INFO: [Epoch 23 / Train]: Train-epoch: last = 6.3434 s, mean = 6.3434 s | Train-step: last = 0.0085988 s, mean = 0.01244 s | #steps/epoch = 469\n",
      "[Epoch 23 / Test]: 100%|██████████| 79/79 [00:01<00:00, 73.33it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:28:13,716 INFO: [Epoch 23 / Test]: Loss = 0.023513\n",
      "colossalai - colossalai - 2022-04-01 23:28:13,717 INFO: [Epoch 23 / Test]: Test-epoch: last = 1.0784 s, mean = 1.0784 s | Test-step: last = 0.0020595 s, mean = 0.013265 s\n",
      "colossalai - colossalai - 2022-04-01 23:28:13,721 INFO: [Epoch 23 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 24 / Train]: 100%|██████████| 469/469 [00:06<00:00, 76.49it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:28:19,984 INFO: [Epoch 24 / Train]: Loss = 0.013507 | LR = 0.001\n",
      "colossalai - colossalai - 2022-04-01 23:28:19,986 INFO: [Epoch 24 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:28:19,988 INFO: [Epoch 24 / Train]: Train-epoch: last = 6.1324 s, mean = 6.1324 s | Train-step: last = 0.0093048 s, mean = 0.012438 s | #steps/epoch = 469\n",
      "[Epoch 24 / Test]: 100%|██████████| 79/79 [00:01<00:00, 75.77it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:28:21,154 INFO: [Epoch 24 / Test]: Loss = 0.024365\n",
      "colossalai - colossalai - 2022-04-01 23:28:21,155 INFO: [Epoch 24 / Test]: Test-epoch: last = 1.0429 s, mean = 1.0429 s | Test-step: last = 0.0015421 s, mean = 0.012897 s\n",
      "colossalai - colossalai - 2022-04-01 23:28:21,157 INFO: [Epoch 24 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 25 / Train]: 100%|██████████| 469/469 [00:06<00:00, 74.58it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:28:27,573 INFO: [Epoch 25 / Train]: Loss = 0.012484 | LR = 0.001\n",
      "colossalai - colossalai - 2022-04-01 23:28:27,575 INFO: [Epoch 25 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:28:27,576 INFO: [Epoch 25 / Train]: Train-epoch: last = 6.289 s, mean = 6.289 s | Train-step: last = 0.0087204 s, mean = 0.012448 s | #steps/epoch = 469\n",
      "[Epoch 25 / Test]: 100%|██████████| 79/79 [00:01<00:00, 77.11it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:28:28,706 INFO: [Epoch 25 / Test]: Loss = 0.023649\n",
      "colossalai - colossalai - 2022-04-01 23:28:28,707 INFO: [Epoch 25 / Test]: Test-epoch: last = 1.0255 s, mean = 1.0255 s | Test-step: last = 0.0020764 s, mean = 0.012611 s\n",
      "colossalai - colossalai - 2022-04-01 23:28:28,713 INFO: [Epoch 25 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 26 / Train]: 100%|██████████| 469/469 [00:06<00:00, 71.35it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:28:35,425 INFO: [Epoch 26 / Train]: Loss = 0.012376 | LR = 0.001\n",
      "colossalai - colossalai - 2022-04-01 23:28:35,428 INFO: [Epoch 26 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:28:35,429 INFO: [Epoch 26 / Train]: Train-epoch: last = 6.574 s, mean = 6.574 s | Train-step: last = 0.0091424 s, mean = 0.012481 s | #steps/epoch = 469\n",
      "[Epoch 26 / Test]: 100%|██████████| 79/79 [00:01<00:00, 71.90it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:28:36,635 INFO: [Epoch 26 / Test]: Loss = 0.023333\n",
      "colossalai - colossalai - 2022-04-01 23:28:36,636 INFO: [Epoch 26 / Test]: Test-epoch: last = 1.0991 s, mean = 1.0991 s | Test-step: last = 0.0016215 s, mean = 0.013571 s\n",
      "colossalai - colossalai - 2022-04-01 23:28:36,639 INFO: [Epoch 26 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 27 / Train]: 100%|██████████| 469/469 [00:06<00:00, 75.52it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:28:42,974 INFO: [Epoch 27 / Train]: Loss = 0.012372 | LR = 0.001\n",
      "colossalai - colossalai - 2022-04-01 23:28:42,977 INFO: [Epoch 27 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:28:42,979 INFO: [Epoch 27 / Train]: Train-epoch: last = 6.211 s, mean = 6.211 s | Train-step: last = 0.008445 s, mean = 0.012485 s | #steps/epoch = 469\n",
      "[Epoch 27 / Test]: 100%|██████████| 79/79 [00:01<00:00, 69.26it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:28:44,229 INFO: [Epoch 27 / Test]: Loss = 0.023465\n",
      "colossalai - colossalai - 2022-04-01 23:28:44,231 INFO: [Epoch 27 / Test]: Test-epoch: last = 1.1417 s, mean = 1.1417 s | Test-step: last = 0.0021236 s, mean = 0.014066 s\n",
      "colossalai - colossalai - 2022-04-01 23:28:44,234 INFO: [Epoch 27 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 28 / Train]: 100%|██████████| 469/469 [00:06<00:00, 74.40it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:28:50,655 INFO: [Epoch 28 / Train]: Loss = 0.012348 | LR = 0.001\n",
      "colossalai - colossalai - 2022-04-01 23:28:50,657 INFO: [Epoch 28 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:28:50,659 INFO: [Epoch 28 / Train]: Train-epoch: last = 6.3048 s, mean = 6.3048 s | Train-step: last = 0.0087955 s, mean = 0.012493 s | #steps/epoch = 469\n",
      "[Epoch 28 / Test]: 100%|██████████| 79/79 [00:01<00:00, 74.95it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:28:51,867 INFO: [Epoch 28 / Test]: Loss = 0.023431\n",
      "colossalai - colossalai - 2022-04-01 23:28:51,868 INFO: [Epoch 28 / Test]: Test-epoch: last = 1.0542 s, mean = 1.0542 s | Test-step: last = 0.0016942 s, mean = 0.012999 s\n",
      "colossalai - colossalai - 2022-04-01 23:28:51,871 INFO: [Epoch 28 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 29 / Train]: 100%|██████████| 469/469 [00:06<00:00, 73.32it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:28:58,417 INFO: [Epoch 29 / Train]: Loss = 0.012349 | LR = 0.001\n",
      "colossalai - colossalai - 2022-04-01 23:28:58,420 INFO: [Epoch 29 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:28:58,422 INFO: [Epoch 29 / Train]: Train-epoch: last = 6.3971 s, mean = 6.3971 s | Train-step: last = 0.0093305 s, mean = 0.012507 s | #steps/epoch = 469\n",
      "[Epoch 29 / Test]: 100%|██████████| 79/79 [00:01<00:00, 73.89it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:28:59,597 INFO: [Epoch 29 / Test]: Loss = 0.023414\n",
      "colossalai - colossalai - 2022-04-01 23:28:59,598 INFO: [Epoch 29 / Test]: Test-epoch: last = 1.0699 s, mean = 1.0699 s | Test-step: last = 0.001745 s, mean = 0.013153 s\n",
      "colossalai - colossalai - 2022-04-01 23:28:59,601 INFO: [Epoch 29 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Testing Dataset: 99.270%\n"
     ]
    }
   ],
   "source": [
    "###===== MultiStep LR Scheduler =====###    \n",
    "train(train_dataloader, test_dataloader,\n",
    "      num_epochs=30, \n",
    "      optim_type='SGD',\n",
    "      lr_start=0.1,\n",
    "      lr_sch='MultiStep',\n",
    "      lr_sch_params={'milestones': [15, 25]},\n",
    "      eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "colossalai - colossalai - 2022-04-01 23:29:04,915 INFO: \n",
      "========== Your Config ========\n",
      "{'BATCH_SIZE': 128, 'NUM_EPOCHS': 30}\n",
      "================================\n",
      "\n",
      "colossalai - colossalai - 2022-04-01 23:29:04,916 INFO: cuDNN benchmark = True, deterministic = False\n",
      "colossalai - colossalai - 2022-04-01 23:29:04,918 WARNING: No PyTorch DDP or gradient handler is set up, please make sure you do not need to all-reduce the gradients after a training step.\n",
      "colossalai - colossalai - 2022-04-01 23:29:04,922 INFO: Using LossHook for training, priority = 0\n",
      "colossalai - colossalai - 2022-04-01 23:29:04,922 INFO: Using LRSchedulerHook for training, priority = 1\n",
      "colossalai - colossalai - 2022-04-01 23:29:04,923 INFO: Using LogMetricByEpochHook for training, priority = 10\n",
      "colossalai - colossalai - 2022-04-01 23:29:04,924 INFO: Using LogMemoryByEpochHook for training, priority = 10\n",
      "colossalai - colossalai - 2022-04-01 23:29:04,925 INFO: Using LogTimingByEpochHook for training, priority = 10\n",
      "colossalai - colossalai - 2022-04-01 23:29:04,925 INFO: Using TensorboardHook for training, priority = 10\n",
      "colossalai - colossalai - 2022-04-01 23:29:04,926 INFO: Lower value means higher priority for calling hook function\n",
      "colossalai - colossalai - 2022-04-01 23:29:04,930 INFO: Before-train: GPU: allocated 0.24 MB, max allocated 15.98 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 0 / Train]: 100%|██████████| 469/469 [00:06<00:00, 73.25it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:29:11,390 INFO: [Epoch 0 / Train]: Loss = 0.96351 | LR = 0.0068961\n",
      "colossalai - colossalai - 2022-04-01 23:29:11,394 INFO: [Epoch 0 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:29:11,395 INFO: [Epoch 0 / Train]: Train-epoch: last = 6.4047 s, mean = 6.4047 s | Train-step: last = 0.0086417 s, mean = 0.012709 s | #steps/epoch = 469\n",
      "[Epoch 0 / Test]: 100%|██████████| 79/79 [00:01<00:00, 72.68it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:29:12,624 INFO: [Epoch 0 / Test]: Loss = 0.28328\n",
      "colossalai - colossalai - 2022-04-01 23:29:12,625 INFO: [Epoch 0 / Test]: Test-epoch: last = 1.0873 s, mean = 1.0873 s | Test-step: last = 0.0030811 s, mean = 0.013358 s\n",
      "colossalai - colossalai - 2022-04-01 23:29:12,629 INFO: [Epoch 0 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 1 / Train]: 100%|██████████| 469/469 [00:06<00:00, 75.77it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:29:18,967 INFO: [Epoch 1 / Train]: Loss = 0.20427 | LR = 0.015235\n",
      "colossalai - colossalai - 2022-04-01 23:29:18,969 INFO: [Epoch 1 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:29:18,970 INFO: [Epoch 1 / Train]: Train-epoch: last = 6.1899 s, mean = 6.1899 s | Train-step: last = 0.0084004 s, mean = 0.01247 s | #steps/epoch = 469\n",
      "[Epoch 1 / Test]: 100%|██████████| 79/79 [00:01<00:00, 75.55it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:29:20,123 INFO: [Epoch 1 / Test]: Loss = 0.11611\n",
      "colossalai - colossalai - 2022-04-01 23:29:20,124 INFO: [Epoch 1 / Test]: Test-epoch: last = 1.0468 s, mean = 1.0468 s | Test-step: last = 0.0021298 s, mean = 0.012884 s\n",
      "colossalai - colossalai - 2022-04-01 23:29:20,128 INFO: [Epoch 1 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 2 / Train]: 100%|██████████| 469/469 [00:06<00:00, 74.31it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:29:26,567 INFO: [Epoch 2 / Train]: Loss = 0.10092 | LR = 0.02801\n",
      "colossalai - colossalai - 2022-04-01 23:29:26,570 INFO: [Epoch 2 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:29:26,571 INFO: [Epoch 2 / Train]: Train-epoch: last = 6.3126 s, mean = 6.3126 s | Train-step: last = 0.017596 s, mean = 0.012504 s | #steps/epoch = 469\n",
      "[Epoch 2 / Test]: 100%|██████████| 79/79 [00:01<00:00, 75.73it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:29:27,728 INFO: [Epoch 2 / Test]: Loss = 0.075374\n",
      "colossalai - colossalai - 2022-04-01 23:29:27,729 INFO: [Epoch 2 / Test]: Test-epoch: last = 1.044 s, mean = 1.044 s | Test-step: last = 0.0020406 s, mean = 0.012852 s\n",
      "colossalai - colossalai - 2022-04-01 23:29:27,733 INFO: [Epoch 2 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 3 / Train]: 100%|██████████| 469/469 [00:06<00:00, 75.69it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:29:34,046 INFO: [Epoch 3 / Train]: Loss = 0.071222 | LR = 0.043681\n",
      "colossalai - colossalai - 2022-04-01 23:29:34,049 INFO: [Epoch 3 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:29:34,050 INFO: [Epoch 3 / Train]: Train-epoch: last = 6.1979 s, mean = 6.1979 s | Train-step: last = 0.0091555 s, mean = 0.01244 s | #steps/epoch = 469\n",
      "[Epoch 3 / Test]: 100%|██████████| 79/79 [00:01<00:00, 74.91it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:29:35,213 INFO: [Epoch 3 / Test]: Loss = 0.058522\n",
      "colossalai - colossalai - 2022-04-01 23:29:35,214 INFO: [Epoch 3 / Test]: Test-epoch: last = 1.0556 s, mean = 1.0556 s | Test-step: last = 0.0020871 s, mean = 0.012984 s\n",
      "colossalai - colossalai - 2022-04-01 23:29:35,218 INFO: [Epoch 3 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 4 / Train]: 100%|██████████| 469/469 [00:06<00:00, 72.94it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:29:41,763 INFO: [Epoch 4 / Train]: Loss = 0.060269 | LR = 0.060355\n",
      "colossalai - colossalai - 2022-04-01 23:29:41,766 INFO: [Epoch 4 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:29:41,767 INFO: [Epoch 4 / Train]: Train-epoch: last = 6.431 s, mean = 6.431 s | Train-step: last = 0.0086515 s, mean = 0.012502 s | #steps/epoch = 469\n",
      "[Epoch 4 / Test]: 100%|██████████| 79/79 [00:01<00:00, 65.45it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:29:43,103 INFO: [Epoch 4 / Test]: Loss = 0.048742\n",
      "colossalai - colossalai - 2022-04-01 23:29:43,104 INFO: [Epoch 4 / Test]: Test-epoch: last = 1.2081 s, mean = 1.2081 s | Test-step: last = 0.0021706 s, mean = 0.014891 s\n",
      "colossalai - colossalai - 2022-04-01 23:29:43,108 INFO: [Epoch 4 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 5 / Train]: 100%|██████████| 469/469 [00:06<00:00, 73.08it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:29:49,655 INFO: [Epoch 5 / Train]: Loss = 0.050693 | LR = 0.076021\n",
      "colossalai - colossalai - 2022-04-01 23:29:49,658 INFO: [Epoch 5 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:29:49,659 INFO: [Epoch 5 / Train]: Train-epoch: last = 6.419 s, mean = 6.419 s | Train-step: last = 0.0085659 s, mean = 0.012543 s | #steps/epoch = 469\n",
      "[Epoch 5 / Test]: 100%|██████████| 79/79 [00:01<00:00, 75.17it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:29:50,818 INFO: [Epoch 5 / Test]: Loss = 0.063858\n",
      "colossalai - colossalai - 2022-04-01 23:29:50,819 INFO: [Epoch 5 / Test]: Test-epoch: last = 1.0516 s, mean = 1.0516 s | Test-step: last = 0.0016429 s, mean = 0.012944 s\n",
      "colossalai - colossalai - 2022-04-01 23:29:50,822 INFO: [Epoch 5 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 6 / Train]: 100%|██████████| 469/469 [00:06<00:00, 77.57it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:29:56,983 INFO: [Epoch 6 / Train]: Loss = 0.047144 | LR = 0.088788\n",
      "colossalai - colossalai - 2022-04-01 23:29:56,986 INFO: [Epoch 6 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:29:56,987 INFO: [Epoch 6 / Train]: Train-epoch: last = 6.0468 s, mean = 6.0468 s | Train-step: last = 0.0087774 s, mean = 0.012465 s | #steps/epoch = 469\n",
      "[Epoch 6 / Test]: 100%|██████████| 79/79 [00:01<00:00, 74.59it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:29:58,153 INFO: [Epoch 6 / Test]: Loss = 0.045778\n",
      "colossalai - colossalai - 2022-04-01 23:29:58,154 INFO: [Epoch 6 / Test]: Test-epoch: last = 1.0599 s, mean = 1.0599 s | Test-step: last = 0.0020866 s, mean = 0.013045 s\n",
      "colossalai - colossalai - 2022-04-01 23:29:58,158 INFO: [Epoch 6 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 7 / Train]: 100%|██████████| 469/469 [00:06<00:00, 75.63it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:30:04,470 INFO: [Epoch 7 / Train]: Loss = 0.040354 | LR = 0.097116\n",
      "colossalai - colossalai - 2022-04-01 23:30:04,472 INFO: [Epoch 7 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:30:04,474 INFO: [Epoch 7 / Train]: Train-epoch: last = 6.2025 s, mean = 6.2025 s | Train-step: last = 0.0087204 s, mean = 0.012445 s | #steps/epoch = 469\n",
      "[Epoch 7 / Test]: 100%|██████████| 79/79 [00:01<00:00, 61.91it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:30:05,867 INFO: [Epoch 7 / Test]: Loss = 0.041521\n",
      "colossalai - colossalai - 2022-04-01 23:30:05,868 INFO: [Epoch 7 / Test]: Test-epoch: last = 1.277 s, mean = 1.277 s | Test-step: last = 0.0022266 s, mean = 0.015749 s\n",
      "colossalai - colossalai - 2022-04-01 23:30:05,872 INFO: [Epoch 7 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 8 / Train]: 100%|██████████| 469/469 [00:06<00:00, 75.59it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:30:12,195 INFO: [Epoch 8 / Train]: Loss = 0.039517 | LR = 0.1\n",
      "colossalai - colossalai - 2022-04-01 23:30:12,198 INFO: [Epoch 8 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:30:12,199 INFO: [Epoch 8 / Train]: Train-epoch: last = 6.2056 s, mean = 6.2056 s | Train-step: last = 0.0080311 s, mean = 0.012438 s | #steps/epoch = 469\n",
      "[Epoch 8 / Test]: 100%|██████████| 79/79 [00:01<00:00, 71.40it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:30:13,411 INFO: [Epoch 8 / Test]: Loss = 0.042419\n",
      "colossalai - colossalai - 2022-04-01 23:30:13,412 INFO: [Epoch 8 / Test]: Test-epoch: last = 1.1074 s, mean = 1.1074 s | Test-step: last = 0.002049 s, mean = 0.01364 s\n",
      "colossalai - colossalai - 2022-04-01 23:30:13,416 INFO: [Epoch 8 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 9 / Train]: 100%|██████████| 469/469 [00:06<00:00, 75.74it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:30:19,724 INFO: [Epoch 9 / Train]: Loss = 0.037427 | LR = 0.099445\n",
      "colossalai - colossalai - 2022-04-01 23:30:19,727 INFO: [Epoch 9 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:30:19,728 INFO: [Epoch 9 / Train]: Train-epoch: last = 6.1931 s, mean = 6.1931 s | Train-step: last = 0.0086725 s, mean = 0.012424 s | #steps/epoch = 469\n",
      "[Epoch 9 / Test]: 100%|██████████| 79/79 [00:01<00:00, 71.75it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:30:20,932 INFO: [Epoch 9 / Test]: Loss = 0.051475\n",
      "colossalai - colossalai - 2022-04-01 23:30:20,934 INFO: [Epoch 9 / Test]: Test-epoch: last = 1.1021 s, mean = 1.1021 s | Test-step: last = 0.0021453 s, mean = 0.013553 s\n",
      "colossalai - colossalai - 2022-04-01 23:30:20,938 INFO: [Epoch 9 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 10 / Train]: 100%|██████████| 469/469 [00:06<00:00, 74.44it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:30:27,355 INFO: [Epoch 10 / Train]: Loss = 0.034638 | LR = 0.097796\n",
      "colossalai - colossalai - 2022-04-01 23:30:27,358 INFO: [Epoch 10 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:30:27,359 INFO: [Epoch 10 / Train]: Train-epoch: last = 6.3014 s, mean = 6.3014 s | Train-step: last = 0.0090749 s, mean = 0.012434 s | #steps/epoch = 469\n",
      "[Epoch 10 / Test]: 100%|██████████| 79/79 [00:01<00:00, 73.97it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:30:28,533 INFO: [Epoch 10 / Test]: Loss = 0.037103\n",
      "colossalai - colossalai - 2022-04-01 23:30:28,534 INFO: [Epoch 10 / Test]: Test-epoch: last = 1.069 s, mean = 1.069 s | Test-step: last = 0.0020597 s, mean = 0.013148 s\n",
      "colossalai - colossalai - 2022-04-01 23:30:28,538 INFO: [Epoch 10 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 11 / Train]: 100%|██████████| 469/469 [00:06<00:00, 74.77it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:30:34,948 INFO: [Epoch 11 / Train]: Loss = 0.035259 | LR = 0.095091\n",
      "colossalai - colossalai - 2022-04-01 23:30:34,951 INFO: [Epoch 11 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:30:34,953 INFO: [Epoch 11 / Train]: Train-epoch: last = 6.2737 s, mean = 6.2737 s | Train-step: last = 0.0092051 s, mean = 0.012437 s | #steps/epoch = 469\n",
      "[Epoch 11 / Test]: 100%|██████████| 79/79 [00:01<00:00, 73.31it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:30:36,137 INFO: [Epoch 11 / Test]: Loss = 0.038283\n",
      "colossalai - colossalai - 2022-04-01 23:30:36,139 INFO: [Epoch 11 / Test]: Test-epoch: last = 1.0783 s, mean = 1.0783 s | Test-step: last = 0.002286 s, mean = 0.013295 s\n",
      "colossalai - colossalai - 2022-04-01 23:30:36,143 INFO: [Epoch 11 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 12 / Train]: 100%|██████████| 469/469 [00:06<00:00, 75.76it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:30:42,472 INFO: [Epoch 12 / Train]: Loss = 0.031247 | LR = 0.09139\n",
      "colossalai - colossalai - 2022-04-01 23:30:42,474 INFO: [Epoch 12 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:30:42,475 INFO: [Epoch 12 / Train]: Train-epoch: last = 6.1914 s, mean = 6.1914 s | Train-step: last = 0.0081911 s, mean = 0.012432 s | #steps/epoch = 469\n",
      "[Epoch 12 / Test]: 100%|██████████| 79/79 [00:01<00:00, 76.50it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:30:43,613 INFO: [Epoch 12 / Test]: Loss = 0.038708\n",
      "colossalai - colossalai - 2022-04-01 23:30:43,615 INFO: [Epoch 12 / Test]: Test-epoch: last = 1.0336 s, mean = 1.0336 s | Test-step: last = 0.0021253 s, mean = 0.012745 s\n",
      "colossalai - colossalai - 2022-04-01 23:30:43,618 INFO: [Epoch 12 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 13 / Train]: 100%|██████████| 469/469 [00:05<00:00, 79.01it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:30:49,687 INFO: [Epoch 13 / Train]: Loss = 0.030214 | LR = 0.086775\n",
      "colossalai - colossalai - 2022-04-01 23:30:49,690 INFO: [Epoch 13 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:30:49,691 INFO: [Epoch 13 / Train]: Train-epoch: last = 5.9365 s, mean = 5.9365 s | Train-step: last = 0.010031 s, mean = 0.012386 s | #steps/epoch = 469\n",
      "[Epoch 13 / Test]: 100%|██████████| 79/79 [00:01<00:00, 74.01it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:30:50,865 INFO: [Epoch 13 / Test]: Loss = 0.035869\n",
      "colossalai - colossalai - 2022-04-01 23:30:50,866 INFO: [Epoch 13 / Test]: Test-epoch: last = 1.0685 s, mean = 1.0685 s | Test-step: last = 0.0020854 s, mean = 0.013139 s\n",
      "colossalai - colossalai - 2022-04-01 23:30:50,870 INFO: [Epoch 13 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 14 / Train]: 100%|██████████| 469/469 [00:06<00:00, 75.56it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:30:57,229 INFO: [Epoch 14 / Train]: Loss = 0.028942 | LR = 0.08135\n",
      "colossalai - colossalai - 2022-04-01 23:30:57,232 INFO: [Epoch 14 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:30:57,234 INFO: [Epoch 14 / Train]: Train-epoch: last = 6.2074 s, mean = 6.2074 s | Train-step: last = 0.0082893 s, mean = 0.01238 s | #steps/epoch = 469\n",
      "[Epoch 14 / Test]: 100%|██████████| 79/79 [00:01<00:00, 71.21it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:30:58,455 INFO: [Epoch 14 / Test]: Loss = 0.034165\n",
      "colossalai - colossalai - 2022-04-01 23:30:58,456 INFO: [Epoch 14 / Test]: Test-epoch: last = 1.1105 s, mean = 1.1105 s | Test-step: last = 0.0021114 s, mean = 0.013682 s\n",
      "colossalai - colossalai - 2022-04-01 23:30:58,460 INFO: [Epoch 14 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 15 / Train]: 100%|██████████| 469/469 [00:06<00:00, 77.27it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:31:04,637 INFO: [Epoch 15 / Train]: Loss = 0.027305 | LR = 0.075236\n",
      "colossalai - colossalai - 2022-04-01 23:31:04,640 INFO: [Epoch 15 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:31:04,641 INFO: [Epoch 15 / Train]: Train-epoch: last = 6.0701 s, mean = 6.0701 s | Train-step: last = 0.0086467 s, mean = 0.012354 s | #steps/epoch = 469\n",
      "[Epoch 15 / Test]: 100%|██████████| 79/79 [00:01<00:00, 74.09it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:31:05,811 INFO: [Epoch 15 / Test]: Loss = 0.036305\n",
      "colossalai - colossalai - 2022-04-01 23:31:05,812 INFO: [Epoch 15 / Test]: Test-epoch: last = 1.0672 s, mean = 1.0672 s | Test-step: last = 0.0020649 s, mean = 0.013125 s\n",
      "colossalai - colossalai - 2022-04-01 23:31:05,816 INFO: [Epoch 15 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 16 / Train]: 100%|██████████| 469/469 [00:05<00:00, 78.78it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:31:11,912 INFO: [Epoch 16 / Train]: Loss = 0.027714 | LR = 0.06857\n",
      "colossalai - colossalai - 2022-04-01 23:31:11,915 INFO: [Epoch 16 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:31:11,916 INFO: [Epoch 16 / Train]: Train-epoch: last = 5.9535 s, mean = 5.9535 s | Train-step: last = 0.0083632 s, mean = 0.01232 s | #steps/epoch = 469\n",
      "[Epoch 16 / Test]: 100%|██████████| 79/79 [00:01<00:00, 77.90it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:31:13,040 INFO: [Epoch 16 / Test]: Loss = 0.035504\n",
      "colossalai - colossalai - 2022-04-01 23:31:13,041 INFO: [Epoch 16 / Test]: Test-epoch: last = 1.0148 s, mean = 1.0148 s | Test-step: last = 0.0021074 s, mean = 0.01252 s\n",
      "colossalai - colossalai - 2022-04-01 23:31:13,044 INFO: [Epoch 16 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 17 / Train]: 100%|██████████| 469/469 [00:06<00:00, 77.12it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:31:19,230 INFO: [Epoch 17 / Train]: Loss = 0.025882 | LR = 0.061499\n",
      "colossalai - colossalai - 2022-04-01 23:31:19,233 INFO: [Epoch 17 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:31:19,235 INFO: [Epoch 17 / Train]: Train-epoch: last = 6.0822 s, mean = 6.0822 s | Train-step: last = 0.0089936 s, mean = 0.012304 s | #steps/epoch = 469\n",
      "[Epoch 17 / Test]: 100%|██████████| 79/79 [00:01<00:00, 74.99it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:31:20,396 INFO: [Epoch 17 / Test]: Loss = 0.035924\n",
      "colossalai - colossalai - 2022-04-01 23:31:20,398 INFO: [Epoch 17 / Test]: Test-epoch: last = 1.0544 s, mean = 1.0544 s | Test-step: last = 0.0025885 s, mean = 0.012993 s\n",
      "colossalai - colossalai - 2022-04-01 23:31:20,402 INFO: [Epoch 17 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 18 / Train]: 100%|██████████| 469/469 [00:06<00:00, 77.70it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:31:26,546 INFO: [Epoch 18 / Train]: Loss = 0.025043 | LR = 0.054183\n",
      "colossalai - colossalai - 2022-04-01 23:31:26,548 INFO: [Epoch 18 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:31:26,550 INFO: [Epoch 18 / Train]: Train-epoch: last = 6.0368 s, mean = 6.0368 s | Train-step: last = 0.008924 s, mean = 0.012286 s | #steps/epoch = 469\n",
      "[Epoch 18 / Test]: 100%|██████████| 79/79 [00:01<00:00, 76.09it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:31:27,693 INFO: [Epoch 18 / Test]: Loss = 0.033766\n",
      "colossalai - colossalai - 2022-04-01 23:31:27,694 INFO: [Epoch 18 / Test]: Test-epoch: last = 1.0386 s, mean = 1.0386 s | Test-step: last = 0.0019965 s, mean = 0.012836 s\n",
      "colossalai - colossalai - 2022-04-01 23:31:27,697 INFO: [Epoch 18 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 19 / Train]: 100%|██████████| 469/469 [00:06<00:00, 78.10it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:31:33,833 INFO: [Epoch 19 / Train]: Loss = 0.023784 | LR = 0.046785\n",
      "colossalai - colossalai - 2022-04-01 23:31:33,836 INFO: [Epoch 19 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:31:33,838 INFO: [Epoch 19 / Train]: Train-epoch: last = 6.006 s, mean = 6.006 s | Train-step: last = 0.0082719 s, mean = 0.012265 s | #steps/epoch = 469\n",
      "[Epoch 19 / Test]: 100%|██████████| 79/79 [00:01<00:00, 75.80it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:31:34,987 INFO: [Epoch 19 / Test]: Loss = 0.038437\n",
      "colossalai - colossalai - 2022-04-01 23:31:34,988 INFO: [Epoch 19 / Test]: Test-epoch: last = 1.0432 s, mean = 1.0432 s | Test-step: last = 0.0020475 s, mean = 0.012831 s\n",
      "colossalai - colossalai - 2022-04-01 23:31:34,992 INFO: [Epoch 19 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 20 / Train]: 100%|██████████| 469/469 [00:06<00:00, 76.81it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:31:41,207 INFO: [Epoch 20 / Train]: Loss = 0.021938 | LR = 0.03947\n",
      "colossalai - colossalai - 2022-04-01 23:31:41,210 INFO: [Epoch 20 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:31:41,212 INFO: [Epoch 20 / Train]: Train-epoch: last = 6.1074 s, mean = 6.1074 s | Train-step: last = 0.0078645 s, mean = 0.012254 s | #steps/epoch = 469\n",
      "[Epoch 20 / Test]: 100%|██████████| 79/79 [00:01<00:00, 72.47it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:31:42,409 INFO: [Epoch 20 / Test]: Loss = 0.032711\n",
      "colossalai - colossalai - 2022-04-01 23:31:42,409 INFO: [Epoch 20 / Test]: Test-epoch: last = 1.0907 s, mean = 1.0907 s | Test-step: last = 0.001615 s, mean = 0.013406 s\n",
      "colossalai - colossalai - 2022-04-01 23:31:42,412 INFO: [Epoch 20 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 21 / Train]: 100%|██████████| 469/469 [00:06<00:00, 74.62it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:31:48,805 INFO: [Epoch 21 / Train]: Loss = 0.02141 | LR = 0.032401\n",
      "colossalai - colossalai - 2022-04-01 23:31:48,808 INFO: [Epoch 21 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:31:48,810 INFO: [Epoch 21 / Train]: Train-epoch: last = 6.286 s, mean = 6.286 s | Train-step: last = 0.0075364 s, mean = 0.012265 s | #steps/epoch = 469\n",
      "[Epoch 21 / Test]: 100%|██████████| 79/79 [00:01<00:00, 77.99it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:31:49,928 INFO: [Epoch 21 / Test]: Loss = 0.029091\n",
      "colossalai - colossalai - 2022-04-01 23:31:49,929 INFO: [Epoch 21 / Test]: Test-epoch: last = 1.0136 s, mean = 1.0136 s | Test-step: last = 0.0021074 s, mean = 0.012446 s\n",
      "colossalai - colossalai - 2022-04-01 23:31:49,933 INFO: [Epoch 21 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 22 / Train]: 100%|██████████| 469/469 [00:06<00:00, 76.42it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:31:56,187 INFO: [Epoch 22 / Train]: Loss = 0.019232 | LR = 0.025736\n",
      "colossalai - colossalai - 2022-04-01 23:31:56,190 INFO: [Epoch 22 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:31:56,192 INFO: [Epoch 22 / Train]: Train-epoch: last = 6.138 s, mean = 6.138 s | Train-step: last = 0.0086284 s, mean = 0.012261 s | #steps/epoch = 469\n",
      "[Epoch 22 / Test]: 100%|██████████| 79/79 [00:01<00:00, 73.32it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:31:57,378 INFO: [Epoch 22 / Test]: Loss = 0.030364\n",
      "colossalai - colossalai - 2022-04-01 23:31:57,379 INFO: [Epoch 22 / Test]: Test-epoch: last = 1.0788 s, mean = 1.0788 s | Test-step: last = 0.002085 s, mean = 0.013278 s\n",
      "colossalai - colossalai - 2022-04-01 23:31:57,383 INFO: [Epoch 22 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 23 / Train]: 100%|██████████| 469/469 [00:06<00:00, 77.02it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:32:03,587 INFO: [Epoch 23 / Train]: Loss = 0.017455 | LR = 0.019625\n",
      "colossalai - colossalai - 2022-04-01 23:32:03,590 INFO: [Epoch 23 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:32:03,591 INFO: [Epoch 23 / Train]: Train-epoch: last = 6.0897 s, mean = 6.0897 s | Train-step: last = 0.0079253 s, mean = 0.012253 s | #steps/epoch = 469\n",
      "[Epoch 23 / Test]: 100%|██████████| 79/79 [00:01<00:00, 72.30it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:32:04,786 INFO: [Epoch 23 / Test]: Loss = 0.02744\n",
      "colossalai - colossalai - 2022-04-01 23:32:04,787 INFO: [Epoch 23 / Test]: Test-epoch: last = 1.0935 s, mean = 1.0935 s | Test-step: last = 0.0020051 s, mean = 0.01351 s\n",
      "colossalai - colossalai - 2022-04-01 23:32:04,790 INFO: [Epoch 23 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 24 / Train]: 100%|██████████| 469/469 [00:06<00:00, 77.40it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:32:10,955 INFO: [Epoch 24 / Train]: Loss = 0.016076 | LR = 0.014203\n",
      "colossalai - colossalai - 2022-04-01 23:32:10,958 INFO: [Epoch 24 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:32:10,960 INFO: [Epoch 24 / Train]: Train-epoch: last = 6.0612 s, mean = 6.0612 s | Train-step: last = 0.0086899 s, mean = 0.012242 s | #steps/epoch = 469\n",
      "[Epoch 24 / Test]: 100%|██████████| 79/79 [00:01<00:00, 74.70it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:32:12,127 INFO: [Epoch 24 / Test]: Loss = 0.02665\n",
      "colossalai - colossalai - 2022-04-01 23:32:12,128 INFO: [Epoch 24 / Test]: Test-epoch: last = 1.0582 s, mean = 1.0582 s | Test-step: last = 0.0014675 s, mean = 0.013081 s\n",
      "colossalai - colossalai - 2022-04-01 23:32:12,131 INFO: [Epoch 24 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 25 / Train]: 100%|██████████| 469/469 [00:06<00:00, 76.20it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:32:18,414 INFO: [Epoch 25 / Train]: Loss = 0.014434 | LR = 0.0095923\n",
      "colossalai - colossalai - 2022-04-01 23:32:18,416 INFO: [Epoch 25 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:32:18,418 INFO: [Epoch 25 / Train]: Train-epoch: last = 6.1556 s, mean = 6.1556 s | Train-step: last = 0.0084875 s, mean = 0.01224 s | #steps/epoch = 469\n",
      "[Epoch 25 / Test]: 100%|██████████| 79/79 [00:01<00:00, 76.58it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:32:19,559 INFO: [Epoch 25 / Test]: Loss = 0.026157\n",
      "colossalai - colossalai - 2022-04-01 23:32:19,560 INFO: [Epoch 25 / Test]: Test-epoch: last = 1.0321 s, mean = 1.0321 s | Test-step: last = 0.0021217 s, mean = 0.01272 s\n",
      "colossalai - colossalai - 2022-04-01 23:32:19,563 INFO: [Epoch 25 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 26 / Train]: 100%|██████████| 469/469 [00:06<00:00, 76.05it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:32:25,834 INFO: [Epoch 26 / Train]: Loss = 0.013286 | LR = 0.0058952\n",
      "colossalai - colossalai - 2022-04-01 23:32:25,836 INFO: [Epoch 26 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:32:25,837 INFO: [Epoch 26 / Train]: Train-epoch: last = 6.1676 s, mean = 6.1676 s | Train-step: last = 0.0093324 s, mean = 0.012241 s | #steps/epoch = 469\n",
      "[Epoch 26 / Test]: 100%|██████████| 79/79 [00:01<00:00, 70.36it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:32:27,086 INFO: [Epoch 26 / Test]: Loss = 0.026258\n",
      "colossalai - colossalai - 2022-04-01 23:32:27,087 INFO: [Epoch 26 / Test]: Test-epoch: last = 1.1232 s, mean = 1.1232 s | Test-step: last = 0.0019438 s, mean = 0.013883 s\n",
      "colossalai - colossalai - 2022-04-01 23:32:27,089 INFO: [Epoch 26 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 27 / Train]: 100%|██████████| 469/469 [00:06<00:00, 75.63it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:32:33,446 INFO: [Epoch 27 / Train]: Loss = 0.012461 | LR = 0.0031945\n",
      "colossalai - colossalai - 2022-04-01 23:32:33,448 INFO: [Epoch 27 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:32:33,450 INFO: [Epoch 27 / Train]: Train-epoch: last = 6.2021 s, mean = 6.2021 s | Train-step: last = 0.0085225 s, mean = 0.012245 s | #steps/epoch = 469\n",
      "[Epoch 27 / Test]: 100%|██████████| 79/79 [00:01<00:00, 75.09it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:32:34,614 INFO: [Epoch 27 / Test]: Loss = 0.024696\n",
      "colossalai - colossalai - 2022-04-01 23:32:34,615 INFO: [Epoch 27 / Test]: Test-epoch: last = 1.053 s, mean = 1.053 s | Test-step: last = 0.0020819 s, mean = 0.01294 s\n",
      "colossalai - colossalai - 2022-04-01 23:32:34,619 INFO: [Epoch 27 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 28 / Train]: 100%|██████████| 469/469 [00:06<00:00, 76.93it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:32:40,869 INFO: [Epoch 28 / Train]: Loss = 0.011979 | LR = 0.0015505\n",
      "colossalai - colossalai - 2022-04-01 23:32:40,873 INFO: [Epoch 28 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:32:40,876 INFO: [Epoch 28 / Train]: Train-epoch: last = 6.0967 s, mean = 6.0967 s | Train-step: last = 0.0072234 s, mean = 0.012237 s | #steps/epoch = 469\n",
      "[Epoch 28 / Test]: 100%|██████████| 79/79 [00:01<00:00, 76.66it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:32:42,015 INFO: [Epoch 28 / Test]: Loss = 0.024607\n",
      "colossalai - colossalai - 2022-04-01 23:32:42,016 INFO: [Epoch 28 / Test]: Test-epoch: last = 1.0313 s, mean = 1.0313 s | Test-step: last = 0.0020361 s, mean = 0.012698 s\n",
      "colossalai - colossalai - 2022-04-01 23:32:42,020 INFO: [Epoch 28 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "[Epoch 29 / Train]: 100%|██████████| 469/469 [00:06<00:00, 77.27it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:32:48,199 INFO: [Epoch 29 / Train]: Loss = 0.01156 | LR = 0.001\n",
      "colossalai - colossalai - 2022-04-01 23:32:48,201 INFO: [Epoch 29 / Train]: GPU: allocated 4.71 MB, max allocated 21.85 MB, cached: 50.0 MB, max cached: 50.0 MB\n",
      "colossalai - colossalai - 2022-04-01 23:32:48,203 INFO: [Epoch 29 / Train]: Train-epoch: last = 6.0705 s, mean = 6.0705 s | Train-step: last = 0.0084457 s, mean = 0.012231 s | #steps/epoch = 469\n",
      "[Epoch 29 / Test]: 100%|██████████| 79/79 [00:01<00:00, 74.25it/s]\n",
      "colossalai - colossalai - 2022-04-01 23:32:49,370 INFO: [Epoch 29 / Test]: Loss = 0.024653\n",
      "colossalai - colossalai - 2022-04-01 23:32:49,371 INFO: [Epoch 29 / Test]: Test-epoch: last = 1.0647 s, mean = 1.0647 s | Test-step: last = 0.0018795 s, mean = 0.013175 s\n",
      "colossalai - colossalai - 2022-04-01 23:32:49,374 INFO: [Epoch 29 / Test]: GPU: allocated 0.72 MB, max allocated 5.82 MB, cached: 50.0 MB, max cached: 50.0 MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Testing Dataset: 99.180%\n"
     ]
    }
   ],
   "source": [
    "###===== OneCycle LR Scheduler =====###    \n",
    "train(train_dataloader, test_dataloader,\n",
    "      num_epochs=30, \n",
    "      optim_type='SGD',\n",
    "      lr_sch='OneCycle',\n",
    "      lr_sch_params={'max_lr': 0.1,\n",
    "                     'final_div_factor': 4},\n",
    "      eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir tb_logs"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "80f70922a413d6d392348c4b1b811219ea06038f8f4a93c2c63c843d96050c64"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
